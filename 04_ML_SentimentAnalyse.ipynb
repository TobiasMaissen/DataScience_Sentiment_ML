{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets optuna scikit-learn matplotlib torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset class to handle tokenized inputs and their corresponding labels.\n",
    "\n",
    "    Attributes:\n",
    "        encodings (dict): Tokenized input data.\n",
    "        labels (list): List of labels corresponding to the input data.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single data sample by index, including inputs and label.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the data sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing tokenized input tensors and label tensor.\n",
    "        \"\"\"\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class EarlyStoppingCallbackCustom(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Custom early stopping callback for the Trainer.\n",
    "\n",
    "    Attributes:\n",
    "        patience (int): Number of evaluations to wait for improvement before stopping.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=2):\n",
    "        self.patience = patience\n",
    "        self.best_loss = None\n",
    "        self.epochs_no_improve = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Called after evaluation; checks if validation loss has improved.\n",
    "\n",
    "        Args:\n",
    "            args: Training arguments.\n",
    "            state: Trainer state.\n",
    "            control: Trainer control.\n",
    "            metrics (dict): Evaluation metrics.\n",
    "        \"\"\"\n",
    "        if metrics is None:\n",
    "            return\n",
    "\n",
    "        eval_loss = metrics.get(\"eval_loss\")\n",
    "        if eval_loss is None:\n",
    "            return\n",
    "\n",
    "        if self.best_loss is None or eval_loss < self.best_loss:\n",
    "            self.best_loss = eval_loss\n",
    "            self.epochs_no_improve = 0\n",
    "            control.should_save = True  # Save the model if it has improved\n",
    "        else:\n",
    "            self.epochs_no_improve += 1\n",
    "            if self.epochs_no_improve >= self.patience:\n",
    "                print(f\"Validation loss has not improved for {self.patience} evaluations. Stopping training.\")\n",
    "                control.should_training_stop = True\n",
    "\n",
    "\n",
    "class CustomTrainingArguments(TrainingArguments):\n",
    "    \"\"\"\n",
    "    Custom training arguments class to include optimizer selection.\n",
    "\n",
    "    Attributes:\n",
    "        optimizer (str): Name of the optimizer to use.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, optimizer=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Custom Trainer class to create optimizer based on provided arguments.\n",
    "    \"\"\"\n",
    "    def create_optimizer(self):\n",
    "        \"\"\"\n",
    "        Overrides the default optimizer creation to use custom optimizer.\n",
    "        \"\"\"\n",
    "        optimizer_name = self.args.optimizer\n",
    "        if optimizer_name == \"adamw\":\n",
    "            optimizer_cls = torch.optim.AdamW\n",
    "            optimizer_kwargs = {\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            }\n",
    "        elif optimizer_name == \"adafactor\":\n",
    "            from transformers.optimization import Adafactor\n",
    "            optimizer_cls = Adafactor\n",
    "            optimizer_kwargs = {\n",
    "                \"lr\": self.args.learning_rate,\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "                \"scale_parameter\": False,\n",
    "                \"relative_step\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "        self.optimizer = optimizer_cls(self.model.parameters(), **optimizer_kwargs)\n",
    "        return self.optimizer\n",
    "\n",
    "\n",
    "class Maissen:\n",
    "    \"\"\"\n",
    "    A class to handle model training with k-fold cross-validation and hyperparameter optimization.\n",
    "\n",
    "    Attributes:\n",
    "        model_names (list): List of model names to train.\n",
    "        data_path (str): Path to the training data CSV file.\n",
    "        save_base_dir (str): Directory to save models and results.\n",
    "        use_drive (bool): Whether to use Google Drive for storage.\n",
    "        hpo_n_trials (int): Number of trials for hyperparameter optimization.\n",
    "        k_folds (int): Number of folds for cross-validation.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_names, use_drive=False, hpo_n_trials=17, k_folds=5):\n",
    "        self.model_names = model_names\n",
    "        self.use_drive = use_drive\n",
    "        self.hpo_n_trials = hpo_n_trials\n",
    "        self.k_folds = k_folds\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.training_args = None\n",
    "        self.trainer = None\n",
    "\n",
    "        # Adjust paths if using Google Drive\n",
    "        if self.use_drive:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            self.data_path = \"/content/drive/MyDrive/MAS DataScience/CAS_ML/training_data.csv\"\n",
    "            self.save_base_dir = \"/content/drive/MyDrive/MAS DataScience/CAS_ML/saved_models\"\n",
    "        else:\n",
    "            self.data_path = \"training_data.csv\"\n",
    "            self.save_base_dir = \"./saved_models\"\n",
    "\n",
    "        os.makedirs(self.save_base_dir, exist_ok=True)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from CSV and processes it into texts and labels.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing lists of texts and labels.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        df = df[['relevant_sentence', 'label']]\n",
    "        label_map = {'negativ': 0, 'neutral': 1, 'positiv': 2}\n",
    "        df['label'] = df['label'].map(label_map)\n",
    "        texts = df['relevant_sentence'].tolist()\n",
    "        labels = df['label'].tolist()\n",
    "        \n",
    "        return texts, labels\n",
    "\n",
    "    def prepare_dataset(self, texts, labels):\n",
    "        \"\"\"\n",
    "        Tokenizes texts and creates a SentimentDataset.\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of input texts.\n",
    "            labels (list): List of labels.\n",
    "\n",
    "        Returns:\n",
    "            SentimentDataset: A dataset containing tokenized inputs and labels.\n",
    "        \"\"\"\n",
    "        encodings = self.tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
    "        return SentimentDataset(encodings, labels)\n",
    "\n",
    "    def initialize_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Initializes the tokenizer and model with the specified name.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Name of the pretrained model.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name  # Store the model name for later use\n",
    "\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Load model configuration with the correct number of labels\n",
    "        model_config = AutoConfig.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "        # Load model with configuration\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            config=model_config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def set_training_arguments(self, output_dir='./results', **kwargs):\n",
    "        \"\"\"\n",
    "        Sets up training arguments for the Trainer.\n",
    "\n",
    "        Args:\n",
    "            output_dir (str): Directory to save training outputs.\n",
    "            **kwargs: Additional keyword arguments for TrainingArguments.\n",
    "        \"\"\"\n",
    "        self.training_args = CustomTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=10,\n",
    "            disable_tqdm=True,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def perform_hyperparameter_search(self, texts, labels):\n",
    "        \"\"\"\n",
    "        Performs hyperparameter optimization using k-fold cross-validation.\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of input texts.\n",
    "            labels (list): List of labels.\n",
    "\n",
    "        Returns:\n",
    "            dict: The best hyperparameters found during optimization.\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            # Suggest hyperparameters\n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "            per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32])\n",
    "            num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [2, 5, 10])\n",
    "            weight_decay = trial.suggest_categorical(\"weight_decay\", [0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n",
    "            warmup_steps = trial.suggest_int(\"warmup_steps\", 0, 300)\n",
    "            optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adamw\", \"adafactor\"])\n",
    "\n",
    "            # Initialize the model-config for this trial\n",
    "            model_config = AutoConfig.from_pretrained(self.model_name, num_labels=3)\n",
    "            \n",
    "            # Initialize the model for this trial\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                self.model_name, config=model_config, ignore_mismatched_sizes=True\n",
    "            )\n",
    "\n",
    "            # Self-made Cross-validation\n",
    "            skf = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=42)\n",
    "            val_losses = []\n",
    "\n",
    "            for fold, (train_index, val_index) in enumerate(skf.split(texts, labels)):\n",
    "                print(f\"\\n--- Hyperparameter Tuning Fold {fold + 1}/{self.k_folds} ---\")\n",
    "\n",
    "                # Prepare data for current fold\n",
    "                train_texts = [texts[i] for i in train_index]\n",
    "                val_texts = [texts[i] for i in val_index]\n",
    "                train_labels = [labels[i] for i in train_index]\n",
    "                val_labels = [labels[i] for i in val_index]\n",
    "\n",
    "                train_dataset = self.prepare_dataset(train_texts, train_labels)\n",
    "                val_dataset = self.prepare_dataset(val_texts, val_labels)\n",
    "\n",
    "                # Set training arguments\n",
    "                training_args = CustomTrainingArguments(\n",
    "                    output_dir=f'./results/trial_{trial.number}_fold_{fold + 1}',\n",
    "                    eval_strategy='epoch',\n",
    "                    save_strategy='no',\n",
    "                    per_device_train_batch_size=per_device_train_batch_size,\n",
    "                    num_train_epochs=num_train_epochs,\n",
    "                    learning_rate=learning_rate,\n",
    "                    weight_decay=weight_decay,\n",
    "                    warmup_steps=warmup_steps,\n",
    "                    optimizer=optimizer_name,\n",
    "                    logging_steps=10,\n",
    "                    disable_tqdm=True\n",
    "                )\n",
    "\n",
    "                trainer = CustomTrainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=val_dataset,\n",
    "                    compute_metrics=self.compute_metrics\n",
    "                )\n",
    "\n",
    "                trainer.train()\n",
    "\n",
    "                # Evaluate on validation set\n",
    "                eval_metrics = trainer.evaluate(eval_dataset=val_dataset)\n",
    "                val_loss = eval_metrics[\"eval_loss\"]\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                # Clean up\n",
    "                del trainer\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            return avg_val_loss\n",
    "\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(objective, n_trials=self.hpo_n_trials)\n",
    "\n",
    "        # Get best hyperparameters\n",
    "        best_hyperparameters = study.best_trial.params\n",
    "\n",
    "        return best_hyperparameters\n",
    "\n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        \"\"\"\n",
    "        Computes evaluation metrics.\n",
    "\n",
    "        Args:\n",
    "            eval_pred (tuple): A tuple containing logits and labels.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of computed metrics.\n",
    "        \"\"\"\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels, predictions, average='weighted', zero_division=1\n",
    "        )\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, best_hyperparameters):\n",
    "        \"\"\"\n",
    "        Trains the model using the provided datasets and hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            train_dataset (Dataset): The training dataset.\n",
    "            val_dataset (Dataset): The validation dataset.\n",
    "            best_hyperparameters (dict): The best hyperparameters to use for training.\n",
    "        \"\"\"\n",
    "        self.set_training_arguments(\n",
    "            output_dir='./temp_trainer',\n",
    "            per_device_train_batch_size=best_hyperparameters['per_device_train_batch_size'],\n",
    "            num_train_epochs=best_hyperparameters['num_train_epochs'],\n",
    "            learning_rate=best_hyperparameters['learning_rate'],\n",
    "            weight_decay=best_hyperparameters['weight_decay'],\n",
    "            warmup_steps=best_hyperparameters['warmup_steps'],\n",
    "            optimizer=best_hyperparameters['optimizer'],\n",
    "            eval_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            load_best_model_at_end=True,\n",
    "            save_total_limit=1,\n",
    "            metric_for_best_model='eval_loss',\n",
    "            greater_is_better=False\n",
    "        )\n",
    "\n",
    "        self.trainer = CustomTrainer(\n",
    "            model=self.model,\n",
    "            args=self.training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallbackCustom()]\n",
    "        )\n",
    "\n",
    "        self.trainer.train()\n",
    "\n",
    "    def evaluate_model(self, eval_dataset):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the provided dataset.\n",
    "\n",
    "        Args:\n",
    "            eval_dataset (Dataset): The dataset to evaluate on.\n",
    "\n",
    "        Returns:\n",
    "            dict: Evaluation metrics.\n",
    "        \"\"\"\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\"Trainer has not been initialized. Please train the model first.\")\n",
    "\n",
    "        eval_metrics = self.trainer.evaluate(eval_dataset=eval_dataset)\n",
    "        return eval_metrics\n",
    "\n",
    "    def save_model(self, save_path, best_hyperparameters):\n",
    "        \"\"\"\n",
    "        Saves the model, tokenizer, and hyperparameters to the specified path.\n",
    "\n",
    "        Args:\n",
    "            save_path (str): The path to save the model.\n",
    "            best_hyperparameters (dict): The best hyperparameters used during training.\n",
    "        \"\"\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.trainer.save_model(save_path)\n",
    "        self.tokenizer.save_pretrained(save_path)\n",
    "        hyperparams_path = os.path.join(save_path, 'best_hyperparams.json')\n",
    "        with open(hyperparams_path, 'w') as f:\n",
    "            json.dump({'best_params': best_hyperparameters}, f, indent=4)\n",
    "        print(f\"Model and hyperparameters saved to: {save_path}\")\n",
    "\n",
    "    def generate_learning_curves(self, texts, labels):\n",
    "        \"\"\"\n",
    "        Generates learning curves for each model using different training sizes.\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of input texts.\n",
    "            labels (list): List of labels.\n",
    "        \"\"\"\n",
    "        saved_models_dir = self.save_base_dir  # Use the directory where models are saved\n",
    "        train_sizes = np.linspace(0.1, 1.0, 5)  # Training sizes from 10% to 100%\n",
    "        learning_curves = {}\n",
    "\n",
    "        # List of saved model directories\n",
    "        model_dirs = [\n",
    "            os.path.join(saved_models_dir, d)\n",
    "            for d in os.listdir(saved_models_dir)\n",
    "            if os.path.isdir(os.path.join(saved_models_dir, d))\n",
    "        ]\n",
    "\n",
    "        for model_dir in model_dirs:\n",
    "            model_name = os.path.basename(model_dir)\n",
    "            print(f\"\\n===== Processing Model: {model_name} =====\")\n",
    "\n",
    "            # Load the best hyperparameters\n",
    "            hyperparams_path = os.path.join(model_dir, 'best_hyperparams.json')\n",
    "            try:\n",
    "                with open(hyperparams_path, 'r') as f:\n",
    "                    hyperparams_data = json.load(f)\n",
    "                best_params = hyperparams_data['best_params']\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading hyperparameters for {model_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Load tokenizer and model\n",
    "            try:\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "                self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model or tokenizer for {model_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Prepare full dataset\n",
    "            try:\n",
    "                full_dataset = self.prepare_dataset(texts, labels)\n",
    "            except Exception as e:\n",
    "                print(f\"Error preparing dataset for {model_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Initialize learning curve data for the model\n",
    "            learning_curves[model_name] = {\n",
    "                'train_sizes': [],\n",
    "                'train_scores': [],\n",
    "                'val_scores': []\n",
    "            }\n",
    "\n",
    "            for size_fraction in train_sizes:\n",
    "                subset_size = int(len(full_dataset) * size_fraction)\n",
    "                if subset_size < 1:\n",
    "                    subset_size = 1  # Ensure at least one example is used\n",
    "\n",
    "                print(f\"  Training size: {subset_size} ({size_fraction*100:.0f}%)\")\n",
    "\n",
    "                # Create a subset of the training dataset\n",
    "                train_subset, _ = random_split(full_dataset, [subset_size, len(full_dataset) - subset_size])\n",
    "\n",
    "                # Split train_subset further into train and validation sets\n",
    "                train_size = int(len(train_subset) * 0.8)\n",
    "                val_size = len(train_subset) - train_size\n",
    "                train_dataset, val_dataset = random_split(train_subset, [train_size, val_size])\n",
    "\n",
    "                # Define training arguments\n",
    "                training_args = CustomTrainingArguments(\n",
    "                    output_dir='./temp_trainer',\n",
    "                    eval_strategy='epoch',\n",
    "                    save_strategy='no',\n",
    "                    logging_dir='./logs',\n",
    "                    per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
    "                    learning_rate=best_params['learning_rate'],\n",
    "                    num_train_epochs=best_params['num_train_epochs'],\n",
    "                    weight_decay=best_params['weight_decay'],\n",
    "                    warmup_steps=best_params['warmup_steps'],\n",
    "                    disable_tqdm=True,  # Avoid excessive output\n",
    "                    optimizer=best_params['optimizer'],\n",
    "                )\n",
    "\n",
    "                # Define trainer\n",
    "                trainer = CustomTrainer(\n",
    "                    model=self.model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=val_dataset,\n",
    "                    compute_metrics=self.compute_metrics\n",
    "                )\n",
    "\n",
    "                # Train the model\n",
    "                try:\n",
    "                    trainer.train()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error training {model_name} with size {subset_size}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Evaluate on training subset\n",
    "                try:\n",
    "                    train_results = trainer.evaluate(eval_dataset=train_dataset)\n",
    "                    train_acc = train_results.get('eval_accuracy', 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating training set for {model_name}: {e}\")\n",
    "                    train_acc = 0\n",
    "\n",
    "                # Evaluate on validation set\n",
    "                try:\n",
    "                    val_results = trainer.evaluate(eval_dataset=val_dataset)\n",
    "                    val_acc = val_results.get('eval_accuracy', 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating validation set for {model_name}: {e}\")\n",
    "                    val_acc = 0\n",
    "\n",
    "                # Store results\n",
    "                learning_curves[model_name]['train_sizes'].append(subset_size)\n",
    "                learning_curves[model_name]['train_scores'].append(train_acc)\n",
    "                learning_curves[model_name]['val_scores'].append(val_acc)\n",
    "\n",
    "                # Optionally: Clean up temporary training directories\n",
    "                try:\n",
    "                    import shutil\n",
    "                    shutil.rmtree('./temp_trainer')\n",
    "                    shutil.rmtree('./logs')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Plot learning curves for the model\n",
    "            plt.figure(figsize=(8, 6))\n",
    "\n",
    "            train_sizes_plot = learning_curves[model_name]['train_sizes']\n",
    "            train_scores = learning_curves[model_name]['train_scores']\n",
    "            val_scores = learning_curves[model_name]['val_scores']\n",
    "\n",
    "            plt.plot(train_sizes_plot, train_scores, 'o-', label='Training Score')\n",
    "            plt.plot(train_sizes_plot, val_scores, 's-', label='Validation Score')\n",
    "\n",
    "            plt.xlabel('Training Size')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Learning Curve for {model_name}')\n",
    "            plt.legend(loc='best')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Clear model from memory to conserve resources\n",
    "            del self.model\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Modelle\n",
    "model_names = [\n",
    "    'deepset/gbert-base',\n",
    "    'aari1995/German_Sentiment',\n",
    "    'oliverguhr/german-sentiment-bert',\n",
    "    'lxyuan/distilbert-base-multilingual-cased-sentiments-student',\n",
    "    'nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    'distilbert-base-german-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'ssary/XLM-RoBERTa-German-sentiment',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung der Maissen-Klasse\n",
    "maissen = Maissen(model_names=model_names, hpo_n_trials=20, use_drive=False, k_folds=5)\n",
    "\n",
    "# Laden der Daten\n",
    "texts, labels = maissen.load_data()\n",
    "\n",
    "# Durchlaufen der Modelle\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n===== Processing Model: {model_name} =====\")\n",
    "    \n",
    "    # Initialisieren des Modells und Tokenizers\n",
    "    maissen.initialize_model(model_name)\n",
    "    \n",
    "    # Hyperparameter-Optimierung\n",
    "    best_hyperparameters = maissen.perform_hyperparameter_search(texts, labels)\n",
    "    print(f\"Best hyperparameters for {model_name}: {best_hyperparameters}\")\n",
    "    \n",
    "    # Vorbereitung des Datasets\n",
    "    full_dataset = maissen.prepare_dataset(texts, labels)\n",
    "    \n",
    "    # Aufteilen in Trainings- und Validierungsdatensatz\n",
    "    train_size = int(len(full_dataset) * 0.8)\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Training des Modells mit den besten Hyperparametern\n",
    "    maissen.train_model(train_dataset, val_dataset, best_hyperparameters)\n",
    "    \n",
    "    # Evaluierung des Modells\n",
    "    eval_metrics = maissen.evaluate_model(val_dataset)\n",
    "    print(f\"Evaluation metrics for {model_name}: {eval_metrics}\")\n",
    "    \n",
    "    # Speichern des Modells\n",
    "    save_path = os.path.join(maissen.save_base_dir, model_name.replace('/', '_'))\n",
    "    maissen.save_model(save_path, best_hyperparameters)\n",
    "    \n",
    "    # Bereinigung für das nächste Modell\n",
    "    del maissen.model\n",
    "    del maissen.trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Generierung von Lernkurven nachdem alle gewünschten Modelle optimiert wurden\n",
    "maissen.generate_learning_curves(texts, labels)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
